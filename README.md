<p align="center">
  <img src="https://img.shields.io/badge/Rust-000000?style=for-the-badge&logo=rust&logoColor=white" alt="Rust">
  <img src="https://img.shields.io/badge/Machine%20Learning-FF6F00?style=for-the-badge&logo=tensorflow&logoColor=white" alt="Machine Learning">
  <img src="https://img.shields.io/badge/Status-Em%20Desenvolvimento-yellow?style=for-the-badge" alt="Status">
</p>

<h1 align="center">ğŸ§  Perceptron em Rust</h1>

<p align="center">
  <strong>ImplementaÃ§Ã£o de um Perceptron do zero, sem frameworks de Machine Learning</strong>
</p>

<p align="center">
  <a href="#-sobre">Sobre</a> â€¢
  <a href="#-motivaÃ§Ã£o">MotivaÃ§Ã£o</a> â€¢
  <a href="#-funcionalidades">Funcionalidades</a> â€¢
  <a href="#-estrutura">Estrutura</a> â€¢
  <a href="#-como-executar">Como Executar</a> â€¢
  <a href="#-referÃªncias">ReferÃªncias</a> â€¢
  <a href="#-licenÃ§a">LicenÃ§a</a>
</p>

---

## ğŸ“– Sobre

Este projeto Ã© uma implementaÃ§Ã£o de um **Perceptron** em **Rust**, baseado nas aulas do canal **[Do Zero](https://www.youtube.com/@dozero)** no YouTube, onde a implementaÃ§Ã£o original Ã© feita em **C**.

O objetivo principal Ã© **aprender os fundamentos de redes neurais** construindo tudo do zero, sem depender de bibliotecas de Machine Learning como TensorFlow ou PyTorch. Aqui, optamos por reescrever o projeto em **Rust** para explorar as vantagens da linguagem em termos de seguranÃ§a de memÃ³ria e performance.

### Como funciona

O perceptron implementado Ã© capaz de aprender funÃ§Ãµes lineares atravÃ©s do algoritmo de **gradiente descendente**:

1. **InicializaÃ§Ã£o**: Pesos e bias sÃ£o inicializados com valores aleatÃ³rios
2. **Forward Pass**: Calcula a saÃ­da do neurÃ´nio: `y = f(Î£(xáµ¢ Ã— wáµ¢) + bias)`
3. **CÃ¡lculo do Custo**: Mede o erro usando MSE (Mean Squared Error)
4. **CÃ¡lculo do Gradiente**: Usa diferenÃ§as finitas para aproximar a derivada
5. **AtualizaÃ§Ã£o**: Ajusta pesos e bias na direÃ§Ã£o que reduz o erro

> âš ï¸ **Nota:** Este Ã© um projeto de **estudo** e nÃ£o deve ser utilizado em produÃ§Ã£o. O foco estÃ¡ no aprendizado dos conceitos fundamentais de redes neurais artificiais.

---

## ğŸ¯ MotivaÃ§Ã£o

- ğŸ“š **Aprendizado**: Compreender os conceitos fundamentais de redes neurais na prÃ¡tica
- ğŸ¦€ **Rust**: Praticar a linguagem Rust em um contexto de Machine Learning
- ğŸ”§ **Do Zero**: Implementar sem abstraÃ§Ãµes para entender "por baixo do capÃ´"
- ğŸ¥ **InspiraÃ§Ã£o**: Acompanhar e adaptar o conteÃºdo do canal Do Zero para Rust

---

## âœ¨ Funcionalidades

- [x] Estrutura bÃ¡sica do NeurÃ´nio (Perceptron)
- [x] InicializaÃ§Ã£o de pesos e bias aleatÃ³rios
- [x] FunÃ§Ã£o de ativaÃ§Ã£o (Identidade)
- [x] ComputaÃ§Ã£o de saÃ­da do neurÃ´nio
- [x] FunÃ§Ã£o de custo MSE (Mean Squared Error)
- [x] CÃ¡lculo de gradiente por diferenÃ§as finitas
- [x] Algoritmo de treinamento (Gradiente Descendente)
- [ ] MÃºltiplas funÃ§Ãµes de ativaÃ§Ã£o (Sigmoid, ReLU, Tanh)
- [ ] MÃºltiplas camadas (MLP - Multi-Layer Perceptron)

---

## ğŸ“ Estrutura

```
perceptron/
â”œâ”€â”€ Cargo.toml          # ConfiguraÃ§Ã£o do projeto e dependÃªncias
â”œâ”€â”€ README.md           # DocumentaÃ§Ã£o do projeto
â””â”€â”€ src/
    â””â”€â”€ main.rs         # ImplementaÃ§Ã£o do perceptron
```

### Componentes Principais

| Componente | DescriÃ§Ã£o |
|------------|-----------|
| `Neuron` | Estrutura que representa um neurÃ´nio com pesos, bias e funÃ§Ã£o de ativaÃ§Ã£o |
| `init_neuron()` | Inicializa um neurÃ´nio com pesos e bias aleatÃ³rios |
| `comput_out()` | Calcula a saÃ­da do neurÃ´nio dado um vetor de entrada |
| `mse()` | Calcula o erro quadrÃ¡tico mÃ©dio (Mean Squared Error) |
| `comput_cost()` | Calcula o custo total do neurÃ´nio para um conjunto de amostras |
| `comput_gradient()` | Calcula o gradiente de um parÃ¢metro usando diferenÃ§as finitas |
| `train()` | Treina o neurÃ´nio usando gradiente descendente |
| `randomize()` | Gera valores aleatÃ³rios em um intervalo |

---

## ğŸš€ Como Executar

### PrÃ©-requisitos

- [Rust](https://www.rust-lang.org/tools/install) instalado (versÃ£o 1.70+)
- Cargo (gerenciador de pacotes do Rust)

### InstalaÃ§Ã£o

```bash
# Clone o repositÃ³rio
git clone https://github.com/strngrthnall/perceptron.git

# Entre no diretÃ³rio
cd perceptron

# Compile o projeto
cargo build --release

# Execute
cargo run
```

### SaÃ­da Esperada

O programa treina um neurÃ´nio para aprender a funÃ§Ã£o linear `y = 2.5x + 6`:

```
***Antes do treinamento***
O custo do neurÃ´nio : 248.5    (valor aleatÃ³rio)
O valor do wheight  : 0.42     (peso aleatÃ³rio)
O valor do bias     : -0.78    (bias aleatÃ³rio)

***Depois do treinamento***
O custo do neurÃ´nio : ~0       (erro mÃ­nimo)
O valor do wheight  : ~2.5     (coeficiente angular aprendido)
O valor do bias     : ~6.0     (termo independente aprendido)
```

> ğŸ’¡ Os valores iniciais sÃ£o aleatÃ³rios, mas apÃ³s 50.000 iteraÃ§Ãµes de treinamento,
> o neurÃ´nio converge para os parÃ¢metros corretos da funÃ§Ã£o `y = 2.5x + 6`.

---

## ğŸ“š ReferÃªncias

- ğŸ¥ **Canal Do Zero** - [YouTube](https://www.youtube.com/@dozero)
  - SÃ©rie de vÃ­deos sobre implementaÃ§Ã£o de redes neurais em C
- ğŸ“– **DocumentaÃ§Ã£o Rust** - [rust-lang.org](https://doc.rust-lang.org/book/)
- ğŸ§  **Perceptron** - [Wikipedia](https://en.wikipedia.org/wiki/Perceptron)

---

## ğŸ› ï¸ Tecnologias

| Tecnologia | VersÃ£o | Uso |
|------------|--------|-----|
| Rust | 2024 Edition | Linguagem principal |
| rand | 0.8 | GeraÃ§Ã£o de nÃºmeros aleatÃ³rios |
| num | 0.4.3 | OperaÃ§Ãµes matemÃ¡ticas |

---

## ğŸ“ LicenÃ§a

Este projeto estÃ¡ sob a licenÃ§a MIT. Veja o arquivo [LICENSE](LICENSE) para mais detalhes.

---

## ğŸ¤ ContribuiÃ§Ã£o

ContribuiÃ§Ãµes sÃ£o bem-vindas! Este Ã© um projeto de estudo, entÃ£o sinta-se Ã  vontade para:

1. Fazer um Fork do projeto
2. Criar uma branch para sua feature (`git checkout -b feature/AmazingFeature`)
3. Commit suas mudanÃ§as (`git commit -m 'Add some AmazingFeature'`)
4. Push para a branch (`git push origin feature/AmazingFeature`)
5. Abrir um Pull Request

---

<p align="center">
  Feito com â¤ï¸ para fins educacionais
</p>

<p align="center">
  <sub>Inspirado nas aulas do canal <a href="https://www.youtube.com/@dozero">Do Zero</a></sub>
</p>
